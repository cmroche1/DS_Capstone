{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03addaa",
   "metadata": {},
   "source": [
    "# Automated Essay Evaluation\n",
    "# SMU, Data Science, Capstone\n",
    "## Chris Roche, Nathan Deinlein, Darryl Dawkins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610218c",
   "metadata": {},
   "source": [
    "#### Brief notes on adding a new criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027e05b",
   "metadata": {},
   "source": [
    "To add a criterion you need to do three main things:\n",
    "    \n",
    "1. Add the call to your model(s) inside a run_criteriaN function\n",
    "   * this function should take in the essay and grade level as params, at a minimum\n",
    "2. Update the output of your run_criteriaN function to be:\n",
    "   * a string to be displayed to the student\n",
    "   * a bool for whether the student needs help in this area (used by recommender)\n",
    "3. Add an initial list of resources for help to the recommender csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b80dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.3.0/en_core_web_md-3.3.0-py3-none-any.whl (33.5 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/anaconda3/lib/python3.8/site-packages (from en-core-web-md==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (1.21.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (2.27.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (61.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (2.11.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (21.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (3.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-md==3.3.0) (2.0.1)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('python -m spacy download en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba92377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/cmroche/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cmroche/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import gradio as gr\n",
    "import spacy\n",
    "import en_core_web_md\n",
    "from statistics import mean, median, mode\n",
    "from TRUNAJOD import surface_proxies\n",
    "import TRUNAJOD.ttr\n",
    "import pytextrank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20021379",
   "metadata": {},
   "source": [
    "### Various functions used for evaluating criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fed540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_bounds(doc):\n",
    "    # Get phrases, vectorize and get sent bounds\n",
    "    limit_phrases = 4\n",
    "\n",
    "    phrase_id = 0\n",
    "    sent_bounds = [ [s.start, s.end, set([])] for s in doc.sents ]\n",
    "\n",
    "    # Loop through each phrase from the document\n",
    "    for p in doc._.phrases:\n",
    "        # Find every sentence the chunk is apert of\n",
    "        # Loop thorugh each phrase chunk\n",
    "        for chunk in p.chunks:\n",
    "            # ic(chunk.start, chunk.end)\n",
    "\n",
    "            # Loop through all sentences in sent_bounds\n",
    "            for sent_start, sent_end, sent_vector in sent_bounds:\n",
    "                # Check if chunk is in the sentence\n",
    "                if chunk.start >= sent_start and chunk.end <= sent_end:\n",
    "                    # ic(sent_start, chunk.start, chunk.end, sent_end)\n",
    "\n",
    "                    # Add phrase_id to sent_vector from sent_bounds\n",
    "                    sent_vector.add(phrase_id)\n",
    "                    break\n",
    "\n",
    "        phrase_id += 1\n",
    "\n",
    "        if phrase_id == limit_phrases:\n",
    "            break\n",
    "    \n",
    "    return sent_bounds\n",
    "\n",
    "def get_unit_vector(key_doc):\n",
    "\n",
    "    # Get phrases, vectorize and get sent bounds\n",
    "    limit_phrases = 4\n",
    "\n",
    "    phrase_id = 0\n",
    "    unit_vector = []\n",
    "\n",
    "    # Loop through each phrase from the document\n",
    "    for p in key_doc._.phrases:\n",
    "\n",
    "        # Add rank to unit_vector list\n",
    "        unit_vector.append(p.rank)\n",
    "\n",
    "        phrase_id += 1\n",
    "\n",
    "        if phrase_id == limit_phrases:\n",
    "            break\n",
    "\n",
    "    return unit_vector\n",
    "\n",
    "def normalize_unit_vector(unit_vector):\n",
    "    # Sum unit vectors for normalization\n",
    "    sum_ranks = sum(unit_vector)\n",
    "\n",
    "    # Normalize unit vector\n",
    "    unit_vector = [ rank/sum_ranks for rank in unit_vector ]\n",
    "\n",
    "    return unit_vector\n",
    "\n",
    "\n",
    "def sent_uv_rank(unit_vector, sent_bounds):\n",
    "    # Ranking each sentence based on how similiar they are,\n",
    "    # in relation to each unit vector, using sum of squares \n",
    "    from math import sqrt\n",
    "\n",
    "    sent_rank = {}\n",
    "    sent_id = 0\n",
    "\n",
    "    # Loop through sent_bound list\n",
    "    for sent_start, sent_end, sent_vector in sent_bounds:\n",
    "        sum_sq = 0.0\n",
    "\n",
    "        # Loop through each phrase in the key vector and\n",
    "        # compare it to the sentence\n",
    "        for phrase_id in range(len(unit_vector)):\n",
    "            # ic(phrase_id, key_unit_vector[phrase_id])\n",
    "\n",
    "            # If phrase_id is NOT in the sent add \n",
    "            # get the sum_sq of the unit_vector length\n",
    "            if phrase_id not in sent_vector:\n",
    "                sum_sq += unit_vector[phrase_id]**2.0\n",
    "\n",
    "        # Get the square root of the sum of squares\n",
    "        sent_rank[sent_id] = sqrt(sum_sq)\n",
    "        sent_id += 1\n",
    "\n",
    "    return sent_rank\n",
    "\n",
    "\n",
    "def get_top_ranks(doc, sent_rank):\n",
    "    from operator import itemgetter\n",
    "    sorted(sent_rank.items(), key=itemgetter(1))\n",
    "\n",
    "    # limit for the number of top sentences to collect\n",
    "    limit_sentences = 5\n",
    "\n",
    "    sent_text = {}\n",
    "    sent_id = 0\n",
    "    top_5_ranks = []\n",
    "    top_5_word_count = []\n",
    "    top_5_lex_div = []\n",
    "\n",
    "    # Create id for each sentence from the document\n",
    "    for sent in doc.sents:\n",
    "        sent_text[sent_id] = sent\n",
    "        sent_id += 1\n",
    "\n",
    "    num_sent = 0\n",
    "\n",
    "    # Loop through sorted sent_rank list\n",
    "    for sent_id, rank in sorted(sent_rank.items(), key=itemgetter(1)):\n",
    "        num_sent += 1\n",
    "        top_5_ranks.append(rank)\n",
    "        \n",
    "        top_5_word_count.append(surface_proxies.word_count(sent_text[sent_id]))\n",
    "        top_5_lex_div.append(TRUNAJOD.ttr.lexical_diversity_mtld(doc))\n",
    "\n",
    "        if num_sent == limit_sentences:\n",
    "            break\n",
    "\n",
    "    rank_avg = mean(top_5_ranks)\n",
    "    rank_med = median(top_5_ranks)\n",
    "    rank_mode = mode(top_5_ranks)\n",
    "\n",
    "    mean_word_count = mean(top_5_word_count)\n",
    "    mean_lex_div = mean(top_5_lex_div)\n",
    "\n",
    "    return rank_avg, rank_med, rank_mode, mean_word_count, mean_lex_div\n",
    "\n",
    "@spacy.registry.misc(\"articles_scrubber\")\n",
    "def articles_scrubber():\n",
    "    def scrubber_func(span: spacy.tokens.Span) -> str:\n",
    "        for token in span:\n",
    "            if token.pos_ not in [\"DET\", \"PRON\", \"ADJ\"]:\n",
    "                break\n",
    "            \n",
    "            span = span[1:]\n",
    "        return span.lemma_\n",
    "    return scrubber_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944577f",
   "metadata": {},
   "source": [
    "#### Criteria 1: Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcea6ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Lexical Diversity Criteria1\n",
    "########################################################\n",
    "\n",
    "# Note: gradeLevel is a string (e.g., \"10th Grade\") but is unused in this proof of concept\n",
    "\n",
    "def run_criteria1(essay, gradeLevel):\n",
    "    needsHelp = False\n",
    "    \n",
    "    # Calculated in the EDA python notebook\n",
    "    modelMedianDiversity = 0.5481\n",
    "    modelMedianTotalWords = 184\n",
    "    modelMedianUniqueWords = 101\n",
    "    \n",
    "    allWords = nltk.tokenize.word_tokenize(essay)\n",
    "    allWords=[allWords.lower() for allWords in allWords if allWords.isalpha()]\n",
    "    \n",
    "    # Get basic statistics about the essay\n",
    "    totalWords = len(allWords)\n",
    "    vocabWords = len(set(allWords))\n",
    "    diversity = vocabWords / totalWords\n",
    "    \n",
    "    # If below average, recommend help\n",
    "    if diversity < modelMedianDiversity:\n",
    "        needsHelp = True\n",
    "    \n",
    "        # Two most common words:\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "        allWordExceptStopDist = nltk.FreqDist(w.lower() for w in allWords if w not in stopwords)\n",
    "        mostCommon= allWordExceptStopDist.most_common(2)\n",
    "        # Source: https://stackoverflow.com/questions/28392860/\n",
    "        #         print-10-most-frequently-occurring-words-of-a-text-that-including-and-excluding\n",
    "        \n",
    "        thesaurusesStr = f\"\"\"I recommend you focus on expanding your vocabulary. For example, your two most common words are '{mostCommon[0][0]}' and '{mostCommon[1][0]}'. Try using alternatives from a thesaurus. \"\"\"\n",
    "\n",
    "    \n",
    "    criteria1OutputStr = f\"\"\"Your essay has {totalWords} total words and {vocabWords} unique words, for a Diversity of {str(round(diversity*100, 2))}%. \"\"\" \n",
    "    criteria1OutputStr = criteria1OutputStr + f\"\"\"{thesaurusesStr if needsHelp else \"Your vocabulary is in good shape! Keep up the good work!\"}\"\"\" \n",
    "        \n",
    "    return criteria1OutputStr, needsHelp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24ed2d",
   "metadata": {},
   "source": [
    "#### Criteria 2: Exteractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae84198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Exteractive Summarization Criteria2\n",
    "########################################################\n",
    "\n",
    "# Note: gradeLevel is a string (e.g., \"10th Grade\") but is unused in this proof of concept\n",
    "\n",
    "def run_criteria2(essay, gradeLevel, essay_prompt):\n",
    "    needsHelp = False\n",
    "    \n",
    "    # Prep the spacy nlp pipeline\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    nlp.add_pipe(\"textrank\", config={\"scrubber\": {\"@misc\": \"articles_scrubber\"}})\n",
    "    \n",
    "    if essay_prompt:\n",
    "        key_doc = nlp(essay_prompt)\n",
    "    else:\n",
    "        key_doc = False\n",
    "    \n",
    "    # Created by processing a string of text with the nlp object\n",
    "    doc = nlp(essay)\n",
    "    \n",
    "    # Return if error\n",
    "    if not key_doc:\n",
    "        criteria2OutputStr = f\"\"\"Not prompt provided, skipping this criterion.\"\"\"\n",
    "        return criteria2OutputStr, needsHelp\n",
    "\n",
    "    sent_bounds = get_sent_bounds(doc)\n",
    "    key_unit_vector = get_unit_vector(key_doc)\n",
    "    key_unit_vector = normalize_unit_vector(key_unit_vector)\n",
    "    key_sent_rank = sent_uv_rank(key_unit_vector, sent_bounds)\n",
    "    key_rank_mean, key_rank_med, key_rank_mode, key_mean_word_count, key_mean_lex_div = get_top_ranks(doc, key_sent_rank)\n",
    "\n",
    "    # Do they need help?\n",
    "    if key_rank_mean > .35:\n",
    "        criteria2OutputStr = f\"\"\"Your essay appears to follow the topic well. Nice job!\"\"\"\n",
    "        needsHelp = False\n",
    "    \n",
    "    else:\n",
    "        criteria2OutputStr = f\"\"\"Your essay seems to be a little off topic. I recommended working on this area. \"\"\"\n",
    "        needsHelp = True\n",
    "\n",
    "    return criteria2OutputStr, needsHelp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7678b",
   "metadata": {},
   "source": [
    "#### Criteria 3: Word/Sentence Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58986a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Word/Sentence Count Criteria3\n",
    "########################################################\n",
    "\n",
    "# Note: gradeLevel is a string (e.g., \"10th Grade\") but is unused in this proof of concept\n",
    "\n",
    "def run_criteria3(essay, gradeLevel, word_count_req, min_length, max_length):\n",
    "    needsHelp = False\n",
    "\n",
    "    # Prep the spacy nlp pipeline\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    nlp.add_pipe(\"textrank\", config={\"scrubber\": {\"@misc\": \"articles_scrubber\"}})\n",
    "    \n",
    "    # Created by processing a string of text with the nlp object\n",
    "    doc = nlp(essay)\n",
    "    \n",
    "    num_sents = surface_proxies.sentence_count(doc)\n",
    "    word_count = surface_proxies.word_count(doc)\n",
    "    average_sentence_length = surface_proxies.average_sentence_length(doc)\n",
    "    \n",
    "    # Check word count\n",
    "    if word_count > word_count_req:\n",
    "        criteria3OutputStr_wc = f\"\"\"Word count meets the minimum requirement.\"\"\"\n",
    "    \n",
    "    else:\n",
    "        criteria3OutputStr_wc = f\"\"\"Your word count is {word_count}, which is below the word count requirement of {str(int(word_count_req))}.\"\"\"\n",
    "        needsHelp = True\n",
    "\n",
    "    # Check sentence length\n",
    "    if average_sentence_length > max_length:\n",
    "        needsHelp = True\n",
    "        criteria3OutputStr_sl = f\"\"\"Most of your sentences are pretty long for your grade level (avg. {str(int(average_sentence_length))} words), review your paper and double-check for run-on sentences. \"\"\"\n",
    "    \n",
    "    elif average_sentence_length < min_length:\n",
    "        needsHelp = True\n",
    "        criteria3OutputStr_sl = f\"\"\"Most of your sentences are on the shorter side for your grade level (avg. {str(int(average_sentence_length))} words), review your paper and check for fragmented sentences. \"\"\"\n",
    "\n",
    "    else:\n",
    "        criteria3OutputStr_sl = f\"\"\"Your sentences length looks good! Keep up the good work.\"\"\"\n",
    "    \n",
    "    # Format final output string\n",
    "    criteria3OutputStr = criteria3OutputStr_wc + \"\\n\\n\" + criteria3OutputStr_sl\n",
    "\n",
    "    return criteria3OutputStr, needsHelp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a296f9b",
   "metadata": {},
   "source": [
    "#### Recommender Engine Link Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091d959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Recommender Enginer is actually ran from three different UIs. One per criteria. Below is \n",
    "#   just the link to each of those 3 criteria pages. The actually RE itself runs in those other \n",
    "#   UIs and is implemented in the Recommender directory of this repo\n",
    "\n",
    "def run_recommender(recommender_links, needHelp):\n",
    "    \n",
    "    # Initialize empty strings\n",
    "    criteria1ResourceStr = \"\"\n",
    "    criteria2ResourceStr = \"\"\n",
    "    criteria3ResourceStr = \"\"\n",
    "    \n",
    "    # Links to eah criterion's individual RE UI:\n",
    "    output_url_string_1 = \"https://tinyurl.com/46t3j9s6\" ## TODO\n",
    "    output_url_string_2 = \"https://tinyurl.com/46t3j9s6\" ## TODO\n",
    "    output_url_string_3 = \"https://tinyurl.com/46t3j9s6\" ## TODO\n",
    "\n",
    "    if needHelp[0] == True:\n",
    "        # If criteria1 needs help, make the string not empty\n",
    "        criteria1ResourceStr = \"Here's a resource to help expand your vocabulary: \" + output_url_string_1\n",
    "    \n",
    "    if needHelp[1] == True:\n",
    "        # If criteria2 needs help, make the string not empty\n",
    "        criteria2ResourceStr = \"Here's a resource to help you work on essay focus: \" + output_url_string_2\n",
    "\n",
    "    if needHelp[2] == True:\n",
    "        # If criteria3 needs help, make the string not empty\n",
    "        criteria3ResourceStr = \"Here's a resource to help you work to improve length: \" + output_url_string_3\n",
    "\n",
    "    return criteria1ResourceStr, criteria2ResourceStr, criteria3ResourceStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6a9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just parses the checkboxes from the UI\n",
    "\n",
    "def evaluate_criteria(criteria):\n",
    "    runCriteria = [False,False,False]\n",
    "    \n",
    "    if 'Vocabulary' in criteria:\n",
    "        runCriteria[0] = True\n",
    " \n",
    "    if 'Focus' in criteria:\n",
    "        runCriteria[1] = True\n",
    "        \n",
    "    if 'Length' in criteria:\n",
    "        runCriteria[2] = True\n",
    "    \n",
    "    return runCriteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee70d3",
   "metadata": {},
   "source": [
    "#### The function that gets called when the user clicks submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36537cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# This is the function called when you click submit on the UI\n",
    "\n",
    "def run_model_with_feedback(essay, criteria, recommender, gradeLevel, essay_prompt, word_count, sent_min, sent_max):\n",
    "    \n",
    "    ##########################################################\n",
    "    # Placeholders for outputs and variables \n",
    "    ##########################################################\n",
    "    output_highlighted_list = []  # List of tuples. Refer to example below for format\n",
    "    recommender_links = []        # append links to this\n",
    "    \n",
    "    # These get replaced with the results for the UI\n",
    "    criteria1OutputStr = \"Did not run evaluation on Vocabulary Diversity\"\n",
    "    criteria2OutputStr = \"Did not run evaluation on Content/Essay focus\"\n",
    "    criteria3OutputStr = \"Did not run evaluation on word count or sentence length\"\n",
    "    \n",
    "    # Check the essay field wasn't left empty before running models\n",
    "    # Return warning plus three empty criteria results and an empty recommender links\n",
    "    if not essay:\n",
    "        ret=\"Invalid/empty essay field, try again\"\n",
    "        return ret,ret,ret,ret,ret\n",
    "    \n",
    "    # Set these to true if the NLP models say the student needs help\n",
    "    # Then recommender will make a list of resources based on these\n",
    "    needHelp=[False,False,False]\n",
    "    \n",
    "    # Whether the user asked us to evaluate the criteria\n",
    "    runCriteria=evaluate_criteria(criteria)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # All processing gets done in the functions. \n",
    "    # This just passes inputs from UI and gets the output\n",
    "    ##########################################################\n",
    "\n",
    "    ## Criteria1:\n",
    "    if runCriteria[0]:\n",
    "        criteria1OutputStr, needHelp[0] = run_criteria1(essay, gradeLevel)\n",
    "    \n",
    "    ## Criteria2:\n",
    "    if runCriteria[1]:\n",
    "        criteria2OutputStr, needHelp[1] = run_criteria2(essay, gradeLevel, essay_prompt)\n",
    "    \n",
    "    ## Criteria 3:\n",
    "    if runCriteria[2]:\n",
    "        criteria3OutputStr, needHelp[2] = run_criteria3(essay, gradeLevel, word_count, sent_min, sent_max)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # Recommender links:\n",
    "    ##########################################################\n",
    "    if recommender == True:\n",
    "        criteria1Link, criteria2Link, criteria3Link = run_recommender(recommender_links, needHelp)\n",
    "        criteria1OutputStr = criteria1OutputStr + criteria1Link\n",
    "        criteria2OutputStr = criteria2OutputStr + criteria2Link\n",
    "        criteria3OutputStr = criteria3OutputStr + criteria3Link\n",
    "    # Else: do nothing and don't append anything\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # Return the results\n",
    "    ########################################################## \n",
    "    return (f\"\"\"Evaluated student submission on {\" and \".join(criteria)} with recommender turned {\"on\" if recommender else \"off\"}\"\"\", \n",
    "            criteria1OutputStr,\n",
    "            criteria2OutputStr,\n",
    "            criteria3OutputStr)\n",
    "    \n",
    "    \n",
    "    \n",
    "# End function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6eb76f",
   "metadata": {},
   "source": [
    "#### The User Interface code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c75be74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861/\n",
      "Running on public URL: https://42786.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://42786.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7fb08437c2b0>,\n",
       " 'http://127.0.0.1:7861/',\n",
       " 'https://42786.gradio.app')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################################\n",
    "# This is the actual interface code\n",
    "iface = gr.Interface(\n",
    "    \n",
    "    # this is the function call with the UI inputs serving as the arguments\n",
    "    run_model_with_feedback,\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # Inputs to the User Interface\n",
    "    ##########################################################\n",
    "    [\n",
    "        # First argument passed in is the essay, as a string\n",
    "        gr.inputs.Textbox(lines=10, placeholder=\"Copy the body of your essay here...\", default=\"\", label=\"Student Essay:\"),\n",
    "        \n",
    "        # Second set of options are which rubric/criteria to check\n",
    "        gr.inputs.CheckboxGroup( \n",
    "                                [\"Vocabulary\", \"Focus\", \"Length\"], \n",
    "                                default=[\"Vocabulary\", \"Focus\", \"Length\"],\n",
    "                                label=\"Evaluate on which criteria?\"),\n",
    "        \n",
    "        # An option to turn on/off the recommender engine\n",
    "        gr.inputs.Checkbox(label=\"Recommend videos for improvement?\", default=True),\n",
    "        \n",
    "        # Grade Level: only 10th is used right now\n",
    "        gr.inputs.Dropdown([\"10th Grade\", \"N/A\"], label=\"Level\"),\n",
    "        \n",
    "        # Prompt for criteria 2\n",
    "        gr.inputs.Textbox(lines=5, placeholder=\"Paste prompt here if applicable...\", default=\"\", label=\"Prompt or Keywords:\"),\n",
    "        \n",
    "        # Counts for criteria 3\n",
    "        gr.inputs.Number(label=\"word count\", default=150),\n",
    "        gr.inputs.Number(label=\"sentence length min threshoold\", default=25),\n",
    "        gr.inputs.Number(label=\"sentence length max threshoold\", default=15),\n",
    "    ],\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # these are the output components\n",
    "    ##########################################################\n",
    "    [\n",
    "        gr.outputs.Textbox(type=\"str\", label=\"Evaluation:\"),\n",
    "        gr.outputs.Textbox(type=\"str\", label=\"Vocabulary Diversity Results:\"),\n",
    "        gr.outputs.Textbox(type=\"str\", label=\"Focus/Content Results:\"),\n",
    "        gr.outputs.Textbox(type=\"str\", label=\"Length Results:\"),\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # examples the UI lets you select from .. these are optional\n",
    "    ##########################################################\n",
    "    examples=[\n",
    "        [\"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\", \n",
    "           [\"Vocabulary\", \"Focus\", \"Length\"], True, \"10th Grade\", \"Computers and their effect on people\",150,25,15],\n",
    "        [\"Dear local newspaper I think that usieng computers help people becuse if we did not have computers we would not now ehey thing about eneyone or eneything like all of the @CAPS1 I would not now eneything about them but with computers I know alot about them and there lives like @CAPS2 @CAPS3 @CAPS4 got shot in the back of the head and. @CAPS4 got shot to and I know alot about the @ORGANIZATION1 there white people that to fear in to black people and the same with the wars like world @NUM1 and world @NUM2 and the @CAPS5 and @PERSON1 and the @CAPS6 war there was like plain spy palin flying across @LOCATION1 and they shot him down becuse we were trying to see if thay had eney nuculer bombs offer there. And the same with google and yahoo with google you can type in eneything and you will get a answer and most liked a corect answer yahoo and google is great for some worke and products end studying becuse you then you do to and that I think that computer are good.\", \n",
    "           [\"Vocabulary\"], False, \"10th Grade\", \"\",150,25,15],\n",
    "        [\"How @CAPS4 you feel if your favorite book was taken off the shelves of your school or public library? I, along with many other students, @CAPS4 find this discouraging and distastrous, so I do not believe that censorship should affect books that are on the shelves. Otherwise, a demolished love of reading, crushed individuality, and separated population @MONTH1 be born.     Like the beloved @PERSON2 @PERSON2 series by @PERSON1, many books and series are being taken out of libraries' collections due to people in society finding them offensive. In this case, the world of witchcraft in which this story blooms is against some religious beliefs; therefore, some individuals within a religion campaign to have these books banned. Fortunately, none of the libraries I visit, with their eclectic collections, had banned this series, or I @CAPS4 not have the strong thirst for literature as I do now. All books have the potential to pull a student into the wonderful world of reading, like @PERSON2 did for me. So how @CAPS4 you feel if your favorite book was gone from all libraries? Disrespected? That is how I @CAPS4 feel\", \n",
    "           [\"Focus\", \"Length\"], True, \"10th Grade\", \"Censorship in the Libraries\",150,25,15],\n",
    "    ],\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # Other settings for the UI\n",
    "    ##########################################################\n",
    "    allow_flagging=\"never\",\n",
    "    theme=\"default\", #\"default\", \"huggingface\", \"seafoam\", \"grass\", \"peach\", \"dark\",\n",
    "    title='Essay Evaluation and Feedback',\n",
    "    \n",
    "    description=\"This is an automated tool for student essay feedback. Unlike traditional Automated Essay Scoring \\\n",
    "    systems, this tool focuses on modularity and interpretability. The student inputs their essay, determines which \\\n",
    "    criteria to be evaluated on, and then receives instant feedback. Not only does the tool make a determination on \\\n",
    "    the selected criteria, it explains how it reached it's conclusion and then it recommends resources the student \\\n",
    "    can use to improve. The student can then score the resources they were assigned which allows the tool to \\\n",
    "    determine how useful the resources are and improve future recommendations. Currently, it only supports 10th \\\n",
    "    grade.\",\n",
    "    \n",
    "    article=\"Authors: Chris Roche, Nathan Deinlein, Darryl Dawkins. \\\n",
    "             Developed for the Southern Methodist University, M.S. Data Science program\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Lastly, launch the application\n",
    "# adding share=True makes a link you can share for 72hrs\n",
    "iface.launch(share=True)\n",
    "\n",
    "\n",
    "\n",
    "# Documentation with examples:\n",
    "# https://www.gradio.app/docs/\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "### END\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265db1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecb97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f2247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8b93e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
