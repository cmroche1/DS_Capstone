{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03addaa",
   "metadata": {},
   "source": [
    "# Automated Essay Evaluation\n",
    "# SMU, Data Science, Capstone\n",
    "## Chris Roche, Nathan Deinlein, Darryl Dawkins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027e05b",
   "metadata": {},
   "source": [
    "To add a model/criteria you need to do three main things:\n",
    "    \n",
    "1. Add the call to your model inside the run_criteriaN function\n",
    "2. Update the output of your run_criteriaN function to be:\n",
    "   * a string to be displayed to the student\n",
    "   * a bool for whether the student needs help in this area\n",
    "3. Add resources for help to the recommender csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3ff1e",
   "metadata": {},
   "source": [
    "TODO:\n",
    "1. run_recommender function has a string for each criteria with a link. Right now it's just placeholders. Have the recommender engine populate those strings dynamically (criteria1Link, criteria2Link, criteria3Link)\n",
    "2. Add more criteria as necessary. There are about 10 places that need to be updated, but it's pretty strightforward. It'll probbaly take me about 5 minutes. I'll add more as needed.\n",
    "\n",
    "NOTE: when you build the UI, it will display below the cell below, but I recommend clicking the 127.0.0.1 link it creates and run it out of a browser window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e5357b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\OaklandHillsMansion\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\OaklandHillsMansion\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import gradio as gr\n",
    "import spacy\n",
    "import spacy\n",
    "from statistics import mean, median, mode\n",
    "from TRUNAJOD import surface_proxies\n",
    "import TRUNAJOD.ttr\n",
    "import pytextrank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7bd12",
   "metadata": {},
   "source": [
    "### Functions for Essay Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad822a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_bounds(doc):\n",
    "    # Get phrases, vectorize and get sent bounds\n",
    "    limit_phrases = 4\n",
    "\n",
    "    phrase_id = 0\n",
    "    sent_bounds = [ [s.start, s.end, set([])] for s in doc.sents ]\n",
    "\n",
    "    # Loop through each phrase from the document\n",
    "    for p in doc._.phrases:\n",
    "        # ic(phrase_id, p.text, p.rank)\n",
    "\n",
    "        # Find every sentence the chunk is apert of\n",
    "        # Loop thorugh each phrase chunk\n",
    "        for chunk in p.chunks:\n",
    "            # ic(chunk.start, chunk.end)\n",
    "\n",
    "            # Loop through all sentences in sent_bounds\n",
    "            for sent_start, sent_end, sent_vector in sent_bounds:\n",
    "                # Check if chunk is in the sentence\n",
    "                if chunk.start >= sent_start and chunk.end <= sent_end:\n",
    "                    # ic(sent_start, chunk.start, chunk.end, sent_end)\n",
    "\n",
    "                    # Add phrase_id to sent_vector from sent_bounds\n",
    "                    sent_vector.add(phrase_id)\n",
    "                    break\n",
    "\n",
    "        phrase_id += 1\n",
    "\n",
    "        if phrase_id == limit_phrases:\n",
    "            break\n",
    "    \n",
    "    return sent_bounds\n",
    "\n",
    "def get_unit_vector(key_doc):\n",
    "\n",
    "    # Get phrases, vectorize and get sent bounds\n",
    "    limit_phrases = 4\n",
    "\n",
    "    phrase_id = 0\n",
    "    unit_vector = []\n",
    "\n",
    "    # Loop through each phrase from the document\n",
    "    for p in key_doc._.phrases:\n",
    "        # ic(phrase_id, p.text, p.rank)\n",
    "\n",
    "        # Add rank to unit_vector list\n",
    "        unit_vector.append(p.rank)\n",
    "\n",
    "        phrase_id += 1\n",
    "\n",
    "        if phrase_id == limit_phrases:\n",
    "            break\n",
    "\n",
    "    return unit_vector\n",
    "\n",
    "def normalize_unit_vector(unit_vector):\n",
    "    # Sum unit vectors for normalization\n",
    "    sum_ranks = sum(unit_vector)\n",
    "\n",
    "    # Normalize unit vector\n",
    "    unit_vector = [ rank/sum_ranks for rank in unit_vector ]\n",
    "\n",
    "    return unit_vector\n",
    "\n",
    "\n",
    "def sent_uv_rank(unit_vector, sent_bounds):\n",
    "    # Ranking each sentence based on how similiar they are,\n",
    "    # in relation to each unit vector, using sum of squares \n",
    "    from math import sqrt\n",
    "\n",
    "    sent_rank = {}\n",
    "    sent_id = 0\n",
    "\n",
    "    # Loop through sent_bound list\n",
    "    for sent_start, sent_end, sent_vector in sent_bounds:\n",
    "        # ic(sent_vector)\n",
    "        sum_sq = 0.0\n",
    "        # ic\n",
    "\n",
    "        # Loop through each phrase in the key vector and\n",
    "        # compare it to the sentence\n",
    "        for phrase_id in range(len(unit_vector)):\n",
    "            # ic(phrase_id, key_unit_vector[phrase_id])\n",
    "\n",
    "            # If phrase_id is NOT in the sent add \n",
    "            # get the sum_sq of the unit_vector length\n",
    "            if phrase_id not in sent_vector:\n",
    "                sum_sq += unit_vector[phrase_id]**2.0\n",
    "\n",
    "        # Get the square root of the sum of squares\n",
    "        sent_rank[sent_id] = sqrt(sum_sq)\n",
    "        sent_id += 1\n",
    "\n",
    "    return sent_rank\n",
    "\n",
    "\n",
    "def get_top_ranks(doc, sent_rank):\n",
    "    from operator import itemgetter\n",
    "    # sort sent_rank\n",
    "    sorted(sent_rank.items(), key=itemgetter(1))\n",
    "    # print(sorted(sent_rank.items(), key=itemgetter(1)))\n",
    "\n",
    "    # limit for the number of top sentences to collect\n",
    "    limit_sentences = 5\n",
    "\n",
    "    sent_text = {}\n",
    "    sent_id = 0\n",
    "    top_5_ranks = []\n",
    "    top_5_word_count = []\n",
    "    # top_5_avg_sent_len = []\n",
    "    top_5_lex_div = []\n",
    "\n",
    "    # Create id for each sentence from the document\n",
    "    for sent in doc.sents:\n",
    "        sent_text[sent_id] = sent\n",
    "        sent_id += 1\n",
    "\n",
    "    num_sent = 0\n",
    "\n",
    "    # Loop through sorted sent_rank list\n",
    "    for sent_id, rank in sorted(sent_rank.items(), key=itemgetter(1)):\n",
    "        # ic(sent_id, sent_text[sent_id])\n",
    "        num_sent += 1\n",
    "        top_5_ranks.append(rank)\n",
    "        \n",
    "        top_5_word_count.append(surface_proxies.word_count(sent_text[sent_id]))\n",
    "        # top_5_avg_sent_len.append(surface_proxies.average_sentence_length(doc))\n",
    "        top_5_lex_div.append(TRUNAJOD.ttr.lexical_diversity_mtld(doc))\n",
    "\n",
    "        if num_sent == limit_sentences:\n",
    "            break\n",
    "\n",
    "    # print(top_5_ranks)\n",
    "    # min_sent = sent_text[limit_sentences]\n",
    "    # max_sent = sent_text[0]\n",
    "    rank_avg = mean(top_5_ranks)\n",
    "    rank_med = median(top_5_ranks)\n",
    "    rank_mode = mode(top_5_ranks)\n",
    "\n",
    "    mean_word_count = mean(top_5_word_count)\n",
    "    # avg_sent_len = median(top_5_avg_sent_len)\n",
    "    mean_lex_div = mean(top_5_lex_div)\n",
    "\n",
    "    return rank_avg, rank_med, rank_mode, mean_word_count, mean_lex_div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9deec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "@spacy.registry.misc(\"articles_scrubber\")\n",
    "def articles_scrubber():\n",
    "    def scrubber_func(span: spacy.tokens.Span) -> str:\n",
    "        for token in span:\n",
    "            if token.pos_ not in [\"DET\", \"PRON\", \"ADJ\"]:\n",
    "                break\n",
    "            \n",
    "            span = span[1:]\n",
    "        return span.lemma_\n",
    "    return scrubber_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec5c568",
   "metadata": {},
   "source": [
    "### Criteria 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c655267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Lexical Diversity MLTD Criteria1\n",
    "########################################################\n",
    "\n",
    "def run_criteria1(essay, doc):\n",
    "    needsHelp = False\n",
    "    \n",
    "    lexical_score = TRUNAJOD.ttr.lexical_diversity_mtld(doc)\n",
    "    \n",
    "    # Calculated in the EDA python notebook\n",
    "    modelMedianDiversity = 0.5481\n",
    "    modelMedianTotalWords = 184\n",
    "    modelMedianUniqueWords = 101\n",
    "    \n",
    "    allWords = nltk.tokenize.word_tokenize(essay)\n",
    "    allWords=[allWords.lower() for allWords in allWords if allWords.isalpha()]\n",
    "    \n",
    "    # Get basic statistics about the essay\n",
    "    totalWords = len(allWords)\n",
    "    vocabWords = len(set(allWords))\n",
    "    diversity = vocabWords / totalWords\n",
    "    \n",
    "    # If below average, recommend help\n",
    "    if diversity < modelMedianDiversity:\n",
    "        needsHelp = True\n",
    "    \n",
    "        # Two most common words:\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "        allWordExceptStopDist = nltk.FreqDist(w.lower() for w in allWords if w not in stopwords)\n",
    "        mostCommon= allWordExceptStopDist.most_common(2)\n",
    "        # Source: https://stackoverflow.com/questions/28392860/\n",
    "        #         print-10-most-frequently-occurring-words-of-a-text-that-including-and-excluding\n",
    "        \n",
    "        thesaurusesStr = f\"\"\"I recommend you focus on expanding your vocabulary. For example, your two most common words are '{mostCommon[0][0]}' and '{mostCommon[1][0]}'. Try using alternatives from a thesaurus. \"\"\"\n",
    "\n",
    "    \n",
    "    # criteria1OutputStr = f\"\"\"Your essay has {totalWords} total words and {vocabWords} unique words, for a Diversity of {str(round(diversity*100, 2))}%. \"\"\" \n",
    "    criteria1OutputStr = f\"\"\"{thesaurusesStr if needsHelp else \"Your vocabulary is in good shape! Keep up the good work!\"}\"\"\" \n",
    "        \n",
    "    return criteria1OutputStr, needsHelp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a20eec",
   "metadata": {},
   "source": [
    "### Criteria 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae84198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Exteractive Summarization Criteria2\n",
    "########################################################\n",
    "\n",
    "def run_criteria2(doc, key_doc):\n",
    "    needsHelp = False\n",
    "\n",
    "    if not key_doc:\n",
    "        criteria3OutputStr = \"No prompt or key words were entered.\"\n",
    "        return criteria3OutputStr\n",
    "\n",
    "    sent_bounds = get_sent_bounds(doc)\n",
    "    \n",
    "    \n",
    "    key_unit_vector = get_unit_vector(key_doc)\n",
    "    key_unit_vector = normalize_unit_vector(key_unit_vector)\n",
    "    key_sent_rank = sent_uv_rank(key_unit_vector, sent_bounds)\n",
    "  \n",
    "    key_rank_mean, key_rank_med, key_rank_mode, key_mean_word_count, key_mean_lex_div = get_top_ranks(doc, key_sent_rank)\n",
    "\n",
    "    if key_rank_mean > .35:\n",
    "        criteria2OutputStr = f\"\"\"Your essay appears to follow the topic well.\"\"\"\n",
    "    \n",
    "    else:\n",
    "        criteria2OutputStr = f\"\"\"Your essay seems to be a little off topic.\"\"\"\n",
    "\n",
    "    return criteria2OutputStr, needsHelp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6c1c9",
   "metadata": {},
   "source": [
    "### Criteria 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58986a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Word count Criteria3\n",
    "########################################################\n",
    "\n",
    "def run_criteria3(doc, word_count_req, sent_length_tuple):\n",
    "    needsHelp = False\n",
    "    \n",
    "    num_sents = surface_proxies.sentence_count(doc)\n",
    "    word_count = surface_proxies.word_count(doc)\n",
    "    average_sentence_length = surface_proxies.average_sentence_length(doc)\n",
    "\n",
    "    min_length = sent_length_tuple[0]\n",
    "    max_length = sent_length_tuple[1]\n",
    "    \n",
    "    # Check word count\n",
    "    if word_count > word_count_req:\n",
    "        criteria3OutputStr_wc = f\"Word count meets the minimum requirement.\"\n",
    "    \n",
    "    else:\n",
    "        needsHelp = True\n",
    "        criteria3OutputStr_wc = f\"Your word count is {word_count}, which is below the word count requirement of {word_count_req}.\"\n",
    "    \n",
    "    # Check sentence length\n",
    "    if average_sentence_length > max_length:\n",
    "        needsHelp = True\n",
    "        criteria3OutputStr_sl = f\"Most of your sentences seem a to be pretty long, review your paper and check for run-on sentences.\"\n",
    "    \n",
    "    elif average_sentence_length < min_length:\n",
    "        needsHelp = True\n",
    "        criteria3OutputStr_sl = f\"Most of your sentences seem a to be on the shorter side, review your paper and check for fragmented sentences.\"\n",
    "\n",
    "    else:\n",
    "        criteria3OutputStr_sl = f\"Your sentences length looks good! Keep up the good work.\"\n",
    "    \n",
    "    criteria3OutputStr = criteria3OutputStr_wc + \"\\n\\n\" + criteria3OutputStr_sl\n",
    "\n",
    "\n",
    "    return criteria3OutputStr, needsHelp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b58df",
   "metadata": {},
   "source": [
    "### Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "091d959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns resources based on whether the criteria needHelp\n",
    "\n",
    "def run_recommender(recommender_links, needHelp):\n",
    "    \n",
    "    # Initialize empty strings\n",
    "    criteria1ResourceStr = \"\"\n",
    "    criteria2ResourceStr = \"\"\n",
    "    criteria3ResourceStr = \"\"\n",
    "    \n",
    "    ### Use the Multi-Armed Bandit and the csv file recommender_results.csv \n",
    "    #   to populate these url strings:\n",
    "    #\n",
    "    #\n",
    "    #   ...\n",
    "    #\n",
    "    #\n",
    "    # I'm populating it with placeholders here:\n",
    "    output_url_string_1 = \"https://tinyurl.com/46t3j9s6\"\n",
    "    output_url_string_2 = \"https://www.khanacademy.org/humanities/grammar\"\n",
    "    output_url_string_3 = \"https://www.khanacademy.org/humanities/grammar\"\n",
    "\n",
    "    if needHelp[0] == True:\n",
    "        # If criteria1 needs help, make the string not empty\n",
    "        criteria1ResourceStr = \"Here's a resource to help expand your vocabulary: \" + output_url_string_1\n",
    "    \n",
    "    if needHelp[1] == True:\n",
    "        # If criteria2 needs help, make the string not empty\n",
    "        criteria2ResourceStr = \"Here's a resource to help you work on organization: \" + output_url_string_2\n",
    "\n",
    "    if needHelp[2] == True:\n",
    "        # If criteria3 needs help, make the string not empty\n",
    "        criteria3ResourceStr = \"Here's a resource to help you work to improve content: \" + output_url_string_3\n",
    "\n",
    "    return criteria1ResourceStr, criteria2ResourceStr, criteria3ResourceStr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a771134",
   "metadata": {},
   "source": [
    "### Criteria Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a6a9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just parses the checkboxes from the UI\n",
    "\n",
    "def evaluate_criteria(criteria):\n",
    "    runCriteria = [False,False,False]\n",
    "    \n",
    "    if 'Vocabulary' in criteria:\n",
    "        runCriteria[0] = True\n",
    " \n",
    "    if 'Organization' in criteria:\n",
    "        runCriteria[1] = True\n",
    "        \n",
    "    if 'Content' in criteria:\n",
    "        runCriteria[2] = True\n",
    "    \n",
    "    return runCriteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e6fb7c",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36537cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# This is the function called when you click submit on the UI\n",
    "\n",
    "def run_model_with_feedback(essay, criteria, recommender, essayType, essay_propmt, word_count, sent_min, sent_max):\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    \n",
    "    # add PyTextRank to the spaCy pipeline\n",
    "    nlp.add_pipe(\"textrank\", config={\"scrubber\": {\"@misc\": \"articles_scrubber\"}})\n",
    "\n",
    "    ########################################################\n",
    "    # Placeholders for outputs and variables \n",
    "    ##########################################################\n",
    "    output_highlighted_list = []  # List of tuples. Refer to example below for format\n",
    "    recommender_links = []        # append links to this\n",
    "    \n",
    "    # These get replaced with the results for the UI\n",
    "    criteria1OutputStr = \"Did not run evaluation on Vocabulary Diversity\"\n",
    "    criteria2OutputStr = \"Did not run evaluation on Organization\"\n",
    "    criteria3OutputStr = \"Did not run evaluation on Content\"\n",
    "    \n",
    "    # Check the essay field wasn't left empty before running models\n",
    "    # Return warning plus three empty criteria results and an empty recommender links\n",
    "    if not essay:\n",
    "        return f\"\"\"Invalid/empty essay field, try again\"\"\", \"\", \"\", \"\", \"\"\n",
    "\n",
    "    if essay_propmt:\n",
    "        key_doc = nlp(essay_propmt)\n",
    "    \n",
    "    else:\n",
    "        key_doc = False\n",
    "    \n",
    "    # Set these to true if the NLP models say the student needs help\n",
    "    # Then recommender will make a list of resources based on these\n",
    "    needHelp=[False,False,False]\n",
    "    \n",
    "    # Whether the user asked us to evaluate the criteria\n",
    "    runCriteria=evaluate_criteria(criteria)\n",
    "    \n",
    "    ########################################################\n",
    "    # All processing gets done in the functions. This just gets the output\n",
    "    # Shouldn't need to be updated\n",
    "    ##########################################################\n",
    "\n",
    "    # Created by processing a string of text with the nlp object\n",
    "    doc = nlp(essay)\n",
    "\n",
    "    # Make tuple for the sentence length requirements\n",
    "    sent_length_tuple = (sent_min, sent_max)\n",
    "\n",
    "    ## Criteria1:\n",
    "    if runCriteria[0]:\n",
    "        criteria1OutputStr, needHelp[0] = run_criteria1(essay, doc)\n",
    "    \n",
    "    ## Criteria2:\n",
    "    if runCriteria[1]:\n",
    "        criteria2OutputStr, needHelp[1] = run_criteria2(doc, key_doc)\n",
    "    \n",
    "    ## Criteria 3:\n",
    "    if runCriteria[2]:\n",
    "        criteria3OutputStr, needHelp[2] = run_criteria3(doc, word_count, sent_length_tuple)\n",
    "\n",
    "    # ## Criteria 4:\n",
    "    # if runCriteria[3]:\n",
    "    #     criteria4OutputStr, needHelp[3] = run_criteria3(doc, sent_length_tuple)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################################################\n",
    "    # These lines are just for highlighter test\n",
    "    # Force some characters to be highlighted in the output\n",
    "    ##########################################################\n",
    "    counter = 0\n",
    "    for element in essay:\n",
    "        counter = counter + 1\n",
    "        if counter < 5:\n",
    "            output_highlighted_list.append((element,\"Vocabulary\"))\n",
    "        elif (counter < 20 and counter > 15):\n",
    "            output_highlighted_list.append((element,\"Organization\"))\n",
    "        elif (counter < 50 and counter > 40):\n",
    "            output_highlighted_list.append((element,\"Content\"))\n",
    "        else:\n",
    "            output_highlighted_list.append((element, None))\n",
    "    # End code that should be deleted when we have real output    \n",
    "    \n",
    "    # The output is a list of tuples, where the first is the character in the essay\n",
    "    # and the second is which criteria to highlight it for\n",
    "    # Example:\n",
    "        #[('T', None),\n",
    "        # ('h', None),\n",
    "        # ('e', None),\n",
    "        # (' ', None),\n",
    "        # ('f', 'Criteria1'),\n",
    "        # ('a', 'Criteria1'),\n",
    "        # ('s', 'Criteria2'),\n",
    "        # ('t', 'Criteria2')]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # Recommender links:\n",
    "    ##########################################################\n",
    "    if recommender == True:\n",
    "        criteria1Link, criteria2Link, criteria3Link = run_recommender(recommender_links, needHelp)\n",
    "        criteria1OutputStr = criteria1OutputStr + criteria1Link\n",
    "        criteria2OutputStr = criteria2OutputStr + criteria2Link\n",
    "        criteria3OutputStr = criteria3OutputStr + criteria3Link\n",
    "    # Else: do nothing and don't append anything\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"criteria2OutputStr: \", criteria1OutputStr, criteria2OutputStr, criteria3OutputStr)\n",
    "    ##########################################################\n",
    "    # Return the results\n",
    "    ########################################################## \n",
    "    return (f\"\"\"Evaluated student submission on {\" and \".join(criteria)} with recommender turned {\"on\" if recommender else \"off\"}\"\"\", \n",
    "            \n",
    "            criteria1OutputStr,\n",
    "            criteria2OutputStr,\n",
    "            criteria3OutputStr)\n",
    "            #todo: \n",
    "            #output_highlighted_list )\n",
    "    \n",
    "    \n",
    "    \n",
    "# End function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab220b",
   "metadata": {},
   "source": [
    "### Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c75be74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "c:\\Python310\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "c:\\Python310\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865/\n",
      "Running on public URL: https://48304.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://48304.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x24cb6405f60>,\n",
       " 'http://127.0.0.1:7865/',\n",
       " 'https://48304.gradio.app')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None(<Task finishe...> result=None>)\n",
      "handle: <Handle>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criteria2OutputStr:  I recommend you focus on expanding your vocabulary. For example, your two most common words are 'books' and 'beliefs'. Try using alternatives from a thesaurus. Here's a resource to help expand your vocabulary: https://tinyurl.com/46t3j9s6 Your essay appears to follow the topic well. Word count meets the minimum requirement.\n",
      "\n",
      "Most of your sentences seem a to be pretty long, review your paper and check for run-on sentences.Here's a resource to help you work to improve content: https://www.khanacademy.org/humanities/grammar\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "# This is the actual interface code\n",
    "iface = gr.Interface(\n",
    "    # this is the function call with the UI inputs serving as the arguments\n",
    "    run_model_with_feedback,\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # Inputs to the User Interface\n",
    "    ##########################################################\n",
    "    [\n",
    "        # First argument passed in is the essay, as a string\n",
    "        gr.inputs.Textbox(lines=10, placeholder=\"Copy the body of your essay here...\", default=\"\", label=\"Student Essay:\"),\n",
    "        # Second set of options are which rubric/criteria to check\n",
    "        gr.inputs.CheckboxGroup( \n",
    "                                [\"Vocabulary\", \"Organization\", \"Content\"], \n",
    "                                default=[\"Vocabulary\", \"Organization\", \"Content\"],\n",
    "                                label=\"Evaluate on which criteria?\"),\n",
    "        # An option to turn on/off the recommender engine\n",
    "        gr.inputs.Checkbox(label=\"Recommend videos for improvement?\", default=True),\n",
    "        gr.inputs.Dropdown([\"Persuasive/ Narrative/Expository\", \"Source Dependent Responses\", \"N/A\"], label=\"Essay Type\"),\n",
    "        gr.inputs.Textbox(lines=10, placeholder=\"Paste prompt here...\", default=\"\", label=\"Propmt (or Keywords):\"),\n",
    "        gr.inputs.Number(label=\"word count\", default=150),\n",
    "        gr.inputs.Number(label=\"sentence length min threshoold\", default=25),\n",
    "        gr.inputs.Number(label=\"sentence length max threshoold\", default=15),\n",
    "\n",
    "    ],\n",
    "    \n",
    "    ##########################################################\n",
    "    # these are the output components\n",
    "    ##########################################################\n",
    "    [\n",
    "        gr.outputs.Textbox(type=\"str\", label=\"Evaluation:\"),\n",
    "        \n",
    "        gr.outputs.Textbox(type=\"str\", label=\"Vocabulary Diversity Results:\"),\n",
    "        gr.outputs.Textbox(type=\"str\", label=\"Organization Results:\"),\n",
    "        gr.outputs.Textbox(type=\"str\", label=\"Content Results:\"),\n",
    "        # gr.outputs.Textbox(type=\"str\", label=\" Results:\"),\n",
    "        \n",
    "        #todo: \n",
    "        #gr.outputs.HighlightedText(color_map={\"Vocabulary\": \"green\", \"Organization\": \"pink\", \"Content\": \"blue\"}, show_legend=True, label=\"Criteria highlighting:\"),\n",
    "    ],\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # examples the UI lets you select from .. these are optional\n",
    "    ##########################################################\n",
    "    examples=[\n",
    "        [\"How @CAPS4 you feel if your favorite book was taken off the shelves of your school or public library? I, along with many other students, @CAPS4 find this discouraging and distastrous, so I do not believe that censorship should affect books that are on the shelves. Otherwise, a demolished love of reading, crushed individuality, and separated population @MONTH1 be born.     Like the beloved @PERSON2 @PERSON2 series by @PERSON1, many books and series are being taken out of libraries' collections due to people in society finding them offensive. In this case, the world of witchcraft in which this story blooms is against some religious beliefs; therefore, some individuals within a religion campaign to have these books banned. Fortunately, none of the libraries I visit, with their eclectic collections, had banned this series, or I @CAPS4 not have the strong thirst for literature as I do now. All books have the potential to pull a student into the wonderful world of reading, like @PERSON2 did for me, so taking away books that are most likely to spark an interest or start a firework of creativity @CAPS4 not only affect this generation, but the futures of all.          If this censorhip was to be allowed, who is to say what all  could be censored? Who @CAPS4 be the final judge as to what books @CAPS4 be banned? It @CAPS4 all come down to power and who was willing enough to take it. This struggle to be on top has the possibility of seperating people apart like political parties. Disagreements could turn into debates, and those could turn into fights. It can be concluded that people are stubborn for their beliefs, and to have someone choose what everyone is allowed to believe @CAPS4  be wrong. For instance, it @CAPS4 be like an @CAPS1 forcing a @CAPS2 to not believe in @CAPS3; a vegetarian commanding that meat can no longer be eaten; a woman taking away men's voting rights. Censorship @CAPS4 lead to the disrespect of other's opinions, and disrespect is never a beneficial thing.     Each and every person has a different opinion on what is offensive or not, so to censor books @CAPS4 be to censor all individual mentality. Without each person's unique thoughts and beliefs, the world @CAPS4 become similiarly vapid and dull. Differences in beliefs is what adds variety to the population and what makes a person special; additionally, free thought is a right all people should have. If someone was to limit the mental, literary stimulants that are out in the world, the amount of creativity and individuality @CAPS4 decrease.     To conclude, censorship @CAPS4 be a disrespect to individuality, personal beliefs, and the overall joy of reading a good book. Just because one might not believe in what a story says, it does not mean that the piece of literature should be forbidden. No one is being forced to read the books that grace the hundreds of shelves in a library, so if someone is offended, simply do not read it. So how @CAPS4 you feel if your favorite book was gone from all libraries? Disrespected? That is how I @CAPS4 feel\", \n",
    "           [\"Vocabulary\", \"Organization\", \"Content\"], True, \"Persuasive/ Narrative/Expository\", \"Censorship in the Libraries. All of us can think of a book that we hope none of our children or any other children have taken off the shelf. But if I have the right to remove that book from the shelf -- that work I abhor -- then you also have exactly the same right and so does everyone else. And then we have no books left on the shelf for any of us. --Katherine Paterson, Author\"],\n",
    "    ],\n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    # Other settings for the UI\n",
    "    ##########################################################\n",
    "    allow_flagging=\"never\",\n",
    "    theme=\"default\", #\"default\", \"huggingface\", \"seafoam\", \"grass\", \"peach\", \"dark\",\n",
    "    title='Essay Evaluation and Feedback',\n",
    "    \n",
    "    description=\"This is an automated tool for student essay feedback. Unlike traditional Automated Essay Scoring \\\n",
    "    systems, this tool focuses on modularity and interpretability. The student inputs their essay, determines which \\\n",
    "    criteria to be graded on, and then receives instant feedback. Not only does the tool make a determination on \\\n",
    "    the selected criteria, it explains how it reached it's conclusion and then it recommends resources the student \\\n",
    "    can use to improve. The student can then score the resources they were assigned, which allows the tool to \\\n",
    "    determine how useful the resources are and improve future recommendations. Currently, it only supports 10th \\\n",
    "    grade.\",\n",
    "    \n",
    "    article=\"Authors: Chris Roche, Nathan Deinlein, Darryl Dawkins. \\\n",
    "             Developed for the Southern Methodist University, M.S. Data Science program. \\\n",
    "             SMU Data Science Review where this research is published: https://scholar.smu.edu/datasciencereview/all_issues.html \\\n",
    "             GitHub repository: https://github.com/cmroche1/DS_Capstone\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Lastly, launch the application\n",
    "# adding share=True makes a link you can share for 72hrs\n",
    "iface.launch(share=True)\n",
    "\n",
    "\n",
    "\n",
    "# Documentation with examples:\n",
    "# https://www.gradio.app/docs/\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "### END\n",
    "##########################################################"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
